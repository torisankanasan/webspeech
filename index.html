<html lang="ja">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  </head>
  <body>
    <h2>クイズ</h2>
    <button>Start</button>
    <div>
        <p class="phrase">Phrase...</p>
        <p class="result">Right or wrong?</p>
        <p class="output">...diagnostic messages</p>
    </div>
    <script>
        var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
        var SpeechGrammarList = SpeechGrammarList || webkitSpeechGrammarList;
        var SpeechRecognitionEvent = SpeechRecognitionEvent || webkitSpeechRecognitionEvent;

        var phrases = [ '1', '2', '3', '4', '5', 'a', 'b', 'c', '戻る', '次' ,'スタート' ];
        var phrasePara = document.querySelector('.phrase');
        var resultPara = document.querySelector('.result');
        var diagnosticPara = document.querySelector('.output');

        function randomPhrase() {
            var number = Math.floor(Math.random() * phrases.length);
            return number;
        }

        function testSpeech() {
            testBtn.disabled = true;
            testBtn.textContent = 'Test in progress';

            var phrase = phrases[randomPhrase()];
            // To ensure case consistency while checking with the returned output text
            phrase = phrase.toLowerCase();
            phrasePara.textContent = phrase;
            resultPara.textContent = 'Right or wrong?';
            resultPara.style.background = 'rgba(0,0,0,0.2)';
            diagnosticPara.textContent = '...diagnostic messages';

            var grammar = '#JSGF V1.0; grammar phrase; public <phrase> = ' + phrase +';';
            var recognition = new SpeechRecognition();
            var speechRecognitionList = new SpeechGrammarList();
            speechRecognitionList.addFromString(grammar, 1);
            recognition.grammars = speechRecognitionList;
            recognition.lang = 'ja-JP';
            recognition.interimResults = true;
            recognition.maxAlternatives = 1;

            recognition.start();

            recognition.onresult = function(event) {
                var speechResult = event.results[0][0].transcript.toLowerCase();
                diagnosticPara.textContent = 'Speech received: ' + speechResult + '.';
                if(speechResult === phrase) {
                resultPara.textContent = 'I heard the correct phrase!';
                resultPara.style.background = 'lime';
                } else {
                resultPara.textContent = 'That didn\'t sound right.';
                resultPara.style.background = 'red';
                }

                console.log('Confidence: ' + event.results[0][0].confidence);
            }

            recognition.onspeechend = function() {
                recognition.stop();
                testBtn.disabled = false;
                testBtn.textContent = 'Start new test';
            }

            recognition.onerror = function(event) {
                testBtn.disabled = false;
                testBtn.textContent = 'Start new test';
                diagnosticPara.textContent = 'Error occurred in recognition: ' + event.error;
                if (event.error === 'no-speech') {
                    // 無音状態で一定時間が経過した、ということなので再度音声認識をスタート
                    try{
                        recognition.start();
                    }catch(e){
                    /* already started の場合は無視 */
                        console.log(e);
                    }
                }
            }
            
            recognition.onaudiostart = function(event) {
                //Fired when the user agent has started to capture audio.
                console.log('SpeechRecognition.onaudiostart');
            }
            
            recognition.onaudioend = function(event) {
                //Fired when the user agent has finished capturing audio.
                console.log('SpeechRecognition.onaudioend');
            }
            
            recognition.onend = function(event) {
                //Fired when the speech recognition service has disconnected.
                console.log('SpeechRecognition.onend');
                /*try{
                    recognition.start();
                }catch(e){
                    console.log(e);
                }*/
            }
            
            recognition.onnomatch = function(event) {
                //Fired when the speech recognition service returns a final result with no significant recognition. This may involve some degree of recognition, which doesn't meet or exceed the confidence threshold.
                console.log('SpeechRecognition.onnomatch');
            }
            
            recognition.onsoundstart = function(event) {
                //Fired when any sound — recognisable speech or not — has been detected.
                console.log('SpeechRecognition.onsoundstart');
            }
            
            recognition.onsoundend = function(event) {
                //Fired when any sound — recognisable speech or not — has stopped being detected.
                console.log('SpeechRecognition.onsoundend');
            }
            
            recognition.onspeechstart = function (event) {
                //Fired when sound that is recognised by the speech recognition service as speech has been detected.
                console.log('SpeechRecognition.onspeechstart');
            }
            recognition.onstart = function(event) {
                //Fired when the speech recognition service has begun listening to incoming audio with intent to recognize grammars associated with the current SpeechRecognition.
                console.log('SpeechRecognition.onstart');
            }
        }

        var testBtn = document.querySelector('button');

        testBtn.addEventListener('click', testSpeech);
    </script>
  </body>
</html>